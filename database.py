import os
import json
import weaviate
from weaviate.classes.init import Auth
from weaviate.classes.config import DataType, Property, Configure
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_weaviate import WeaviateVectorStore
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
from config import (
    WEAVIATE_URL,
    CLASS_NAME,
    WEAVIATE_API_KEY,
    EMBEDDING_MODEL,
    CHUNK_SIZE,
    CHUNK_OVERLAP,
    TRANSCRIPTS_DIR,
    DATA_DIR,
)

# ë°°ì¹˜ í¬ê¸° ì„¤ì •
BATCH_SIZE = 100


def load_uploaded_files():
    """ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°"""
    uploaded_file = os.path.join(DATA_DIR, "uploaded_files.json")
    try:
        with open(uploaded_file, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        return {"files": []}


def save_uploaded_files(uploaded_files):
    """ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ì €ì¥"""
    uploaded_file = os.path.join(DATA_DIR, "uploaded_files.json")
    with open(uploaded_file, "w") as f:
        json.dump(uploaded_files, f, indent=2)


def init_weaviate_client():
    """Weaviate í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    return weaviate.connect_to_weaviate_cloud(
        cluster_url=WEAVIATE_URL,
        auth_credentials=Auth.api_key(api_key=WEAVIATE_API_KEY),
        skip_init_checks=True,
    )


def init_vector_store(client):
    """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
    embedding = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={"device": "cpu", "trust_remote_code": True},
        encode_kwargs={
            "normalize_embeddings": True,
            "padding": True,
            "max_length": 512,
        },
    )

    if not client.collections.exists(CLASS_NAME):
        client.collections.create(
            name=CLASS_NAME,
            properties=[
                Property(name="content", data_type=DataType.TEXT),
                Property(name="channel_id", data_type=DataType.TEXT),
                Property(name="video_id", data_type=DataType.TEXT),
                Property(name="start", data_type=DataType.NUMBER),
                Property(name="end", data_type=DataType.NUMBER),
            ],
            vectorizer_config=Configure.Vectorizer.none(),
        )

    return WeaviateVectorStore(
        client=client,
        index_name=CLASS_NAME,
        text_key="content",
        embedding=embedding,
    )


def convert_segments_to_docs(channel_id, video_id, segments):
    """ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë¬¸ì„œë¡œ ë³€í™˜"""
    docs = []
    for i in range(0, len(segments), 10):
        group = segments[i : i + 10]
        if not group:
            continue

        combined_text = " ".join(seg["text"] for seg in group)
        doc = Document(
            page_content=combined_text,
            metadata={
                "channel_id": channel_id,
                "video_id": video_id,
                "start": group[0]["start"],
                "end": group[-1]["start"],
            },
        )
        docs.append(doc)
    return docs


def upload_batch(vectorstore, docs_batch):
    """ë¬¸ì„œ ë°°ì¹˜ ì—…ë¡œë“œ"""
    try:
        vectorstore.add_documents(docs_batch)
        return True
    except Exception as e:
        print(f"âŒ ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return False


def upload_to_database():
    """JSON íŒŒì¼ë“¤ì„ DBì— ì—…ë¡œë“œ"""
    client = init_weaviate_client()
    vectorstore = init_vector_store(client)
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP
    )

    # ì±„ë„ ID ì„¤ì •
    channel_id = "UCUj6rrhMTR9pipbAWBAMvUQ"

    # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
    uploaded_files = load_uploaded_files()

    # JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì—…ë¡œë“œë˜ì§€ ì•Šì€ íŒŒì¼ë§Œ)
    json_files = [
        f
        for f in os.listdir(TRANSCRIPTS_DIR)
        if f.endswith(".json") and f not in uploaded_files["files"]
    ]

    total_files = len(json_files)
    if total_files == 0:
        print("âœ… ëª¨ë“  íŒŒì¼ì´ ì´ë¯¸ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    processed_count = 0
    success_count = 0
    failed_count = 0

    print(f"\nğŸ“¤ ì´ {total_files}ê°œ íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘")

    for json_file in json_files:
        try:
            video_id = json_file.replace(".json", "")
            file_path = os.path.join(TRANSCRIPTS_DIR, json_file)

            # JSON íŒŒì¼ ì½ê¸°
            with open(file_path, "r", encoding="utf-8") as f:
                transcript = json.load(f)

            # ë¬¸ì„œ ë³€í™˜
            video_docs = convert_segments_to_docs(channel_id, video_id, transcript)
            if not video_docs:
                print(f"âŒ {video_id}: ë¬¸ì„œ ë³€í™˜ ì‹¤íŒ¨")
                failed_count += 1
                continue

            # ë¬¸ì„œ ë¶„í• 
            split_docs = splitter.split_documents(video_docs)

            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì—…ë¡œë“œ
            for i in range(0, len(split_docs), BATCH_SIZE):
                batch = split_docs[i : i + BATCH_SIZE]
                if upload_batch(vectorstore, batch):
                    print(f"âœ… {video_id}: ë°°ì¹˜ ì—…ë¡œë“œ ì™„ë£Œ ({len(batch)} ë¬¸ì„œ)")
                else:
                    print(f"âŒ {video_id}: ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤íŒ¨")
                    failed_count += 1
                    continue

            # ì—…ë¡œë“œ ì„±ê³µí•œ íŒŒì¼ ê¸°ë¡
            uploaded_files["files"].append(json_file)
            save_uploaded_files(uploaded_files)

            success_count += 1
            print(f"âœ… {video_id}: ì „ì²´ ì—…ë¡œë“œ ì™„ë£Œ")

        except Exception as e:
            print(f"âŒ {video_id}: ì—…ë¡œë“œ ì‹¤íŒ¨ - {str(e)}")
            failed_count += 1

        processed_count += 1
        print(f"\nğŸ“Š ì§„í–‰ ìƒí™©: {processed_count}/{total_files}")
        print(f"âœ… ì„±ê³µ: {success_count}")
        print(f"âŒ ì‹¤íŒ¨: {failed_count}")

    client.close()

    print("\nğŸ“Š ìµœì¢… ì—…ë¡œë“œ ê²°ê³¼:")
    print(f"âœ… ì´ ì²˜ë¦¬ëœ íŒŒì¼: {total_files}")
    print(f"âœ… ì„±ê³µ: {success_count}")
    print(f"âŒ ì‹¤íŒ¨: {failed_count}")

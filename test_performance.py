import requests
import time
import concurrent.futures
import statistics
from datetime import datetime
import json
import os
from config import API_URL  # API_URLì„ configì—ì„œ import

# API ì„œë²„ URLì„ configì—ì„œ ê°€ì ¸ì˜´
API_URL = "http://203.252.147.202:8200/api/search"

# í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬
TEST_RESULTS_DIR = "test_results"
os.makedirs(TEST_RESULTS_DIR, exist_ok=True)

# í…ŒìŠ¤íŠ¸í•  ê²€ìƒ‰ì–´ ëª©ë¡
TEST_QUERIES = [
    "ë‹¤ë¥¸ ì‚¬ëŒì´ ì´ê¸°ëŠ” ê±¸ ì¢‹ì•„í•´ ë´.. ê·¸ëŸ¼ ì•„ë¹ ë„ í–‰ë³µí• ê±¸?",
    "ì´ê±° ì§„ì§œ ì›ƒê¸°ë„¤",
    "ì•„ ì§„ì§œ í™”ë‚˜ë„¤",
    "ì´ê²Œ ë­ì•¼",
    "ì™€ ì§„ì§œ ëŒ€ë°•ì´ë‹¤",
    "ì´ê±° ì–´ë–»ê²Œ í•˜ëŠ” ê±°ì•¼",
    "ì•„ ì§„ì§œ ì–´ë µë‹¤",
    "ì´ê±° ì§„ì§œ ì¬ë¯¸ìˆë‹¤",
    "ì™€ ì§„ì§œ ì‹ ê¸°í•˜ë‹¤",
    "ì´ê±° ì§„ì§œ ì¢‹ë‹¤",
]

# ê²€ìƒ‰ íƒ€ì… ëª©ë¡ (í˜„ì¬ êµ¬í˜„ëœ íƒ€ì…ë§Œ í¬í•¨)
SEARCH_TYPES = [
    "exact_match",
    "vector",
    "vector_no_celery",
]  # Celery ì‚¬ìš© ì—¬ë¶€ ë¹„êµë¥¼ ìœ„í•œ íƒ€ì… ì¶”ê°€


def check_api_health():
    """API ì„œë²„ ìƒíƒœ í™•ì¸"""
    try:
        response = requests.get("http://203.252.147.202:8200/health", timeout=10)
        if response.status_code == 200:
            health_data = response.json()
            print(f"API ì„œë²„ ì‘ë‹µ ì‹œê°„: {response.elapsed.total_seconds():.2f}ì´ˆ")
            return True
        else:
            print(f"API ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
            return False
    except requests.exceptions.ConnectionError:
        print("API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    except requests.exceptions.Timeout:
        print("API ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
        return False
    except Exception as e:
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        return False


def make_search_request(query, search_type="vector"):
    """ë‹¨ì¼ ê²€ìƒ‰ ìš”ì²­ ìˆ˜í–‰ ë° ì‹œê°„ ì¸¡ì •"""
    start_time = time.time()
    try:
        # 1. API ì„œë²„ ì—°ê²° ì‹œë„
        connection_start = time.time()

        # Celery ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥¸ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
        if search_type == "vector_no_celery":
            url = "http://203.252.147.202:8200/api/search_no_celery"
        else:
            url = API_URL

        response = requests.post(
            url, json={"query": query, "search_type": search_type}, timeout=60
        )
        connection_time = time.time() - connection_start

        end_time = time.time()
        processing_time = end_time - start_time

        # ì‘ë‹µ ë‚´ìš© íŒŒì‹±
        response_data = response.json() if response.status_code == 200 else None

        if response.status_code == 200:
            print(
                f"ê²€ìƒ‰ ì™„ë£Œ - ì†Œìš”ì‹œê°„: {processing_time:.2f}ì´ˆ (ì—°ê²°: {connection_time:.2f}ì´ˆ)"
            )

        return {
            "query": query,
            "search_type": search_type,
            "status_code": response.status_code,
            "processing_time": processing_time,
            "connection_time": connection_time,
            "success": response.status_code == 200,
            "error": None if response.status_code == 200 else response.text,
            "response_data": response_data,
            "error_type": (
                "connection_error"
                if "Connection" in str(response.text)
                else "server_error"
            ),
        }
    except requests.exceptions.Timeout:
        end_time = time.time()
        print(f"ìš”ì²­ ì‹œê°„ ì´ˆê³¼ - ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
        return {
            "query": query,
            "search_type": search_type,
            "status_code": None,
            "processing_time": end_time - start_time,
            "connection_time": end_time - start_time,
            "success": False,
            "error": "ìš”ì²­ ì‹œê°„ ì´ˆê³¼",
            "error_type": "timeout_error",
        }
    except requests.exceptions.ConnectionError as e:
        end_time = time.time()
        print(f"ì—°ê²° ì˜¤ë¥˜ - ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
        return {
            "query": query,
            "search_type": search_type,
            "status_code": None,
            "processing_time": end_time - start_time,
            "connection_time": end_time - start_time,
            "success": False,
            "error": str(e),
            "error_type": "connection_error",
        }
    except Exception as e:
        end_time = time.time()
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ - ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
        return {
            "query": query,
            "search_type": search_type,
            "status_code": None,
            "processing_time": end_time - start_time,
            "connection_time": end_time - start_time,
            "success": False,
            "error": str(e),
            "error_type": "unknown_error",
        }


def run_concurrent_test(num_users, num_requests_per_user):
    """ë™ì‹œ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print(f"\ní…ŒìŠ¤íŠ¸ ì‹œì‘: {num_users}ëª…ì˜ ì‚¬ìš©ì, ê° {num_requests_per_user}ê°œ ìš”ì²­")

    all_results = []
    start_time = time.time()

    # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì‹œ ìš”ì²­ ì²˜ë¦¬
    with concurrent.futures.ThreadPoolExecutor(max_workers=num_users) as executor:
        futures = []
        for user_id in range(num_users):
            for query_idx, query in enumerate(TEST_QUERIES[:num_requests_per_user], 1):
                for search_type in SEARCH_TYPES:
                    futures.append(
                        executor.submit(make_search_request, query, search_type)
                    )

        # ê²°ê³¼ ìˆ˜ì§‘
        for future in concurrent.futures.as_completed(futures):
            try:
                result = future.result()
                all_results.append(result)
            except Exception as e:
                print(f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    end_time = time.time()
    total_time = end_time - start_time
    print(f"í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ")

    # ê²°ê³¼ ë¶„ì„
    successful_requests = [r for r in all_results if r["success"]]
    failed_requests = [r for r in all_results if not r["success"]]

    # ê²€ìƒ‰ íƒ€ì…ë³„ ì„±ê³µë¥  ê³„ì‚°
    search_type_stats = {}
    for search_type in SEARCH_TYPES:
        type_requests = [r for r in all_results if r["search_type"] == search_type]
        type_success = [r for r in type_requests if r["success"]]
        search_type_stats[search_type] = {
            "total": len(type_requests),
            "success": len(type_success),
            "success_rate": (
                len(type_success) / len(type_requests) if type_requests else 0
            ),
            "avg_processing_time": (
                statistics.mean([r["processing_time"] for r in type_success])
                if type_success
                else 0
            ),
        }

    # ì—ëŸ¬ íƒ€ì…ë³„ ë¶„ì„
    error_types = {}
    for failed in failed_requests:
        error_type = failed.get("error_type", "unknown")
        error_types[error_type] = error_types.get(error_type, 0) + 1

    # í†µê³„ ê³„ì‚°
    stats = {
        "total_requests": len(all_results),
        "successful_requests": len(successful_requests),
        "failed_requests": len(failed_requests),
        "total_time": total_time,
        "avg_processing_time": (
            statistics.mean([r["processing_time"] for r in successful_requests])
            if successful_requests
            else 0
        ),
        "avg_connection_time": statistics.mean(
            [r["connection_time"] for r in all_results]
        ),
        "error_types": error_types,
        "search_type_stats": search_type_stats,
        "requests_per_second": (len(all_results) / total_time if total_time > 0 else 0),
    }

    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_file = f"{TEST_RESULTS_DIR}/test_results_{timestamp}.json"

    with open(result_file, "w", encoding="utf-8") as f:
        json.dump(
            {
                "test_config": {
                    "num_users": num_users,
                    "num_requests_per_user": num_requests_per_user,
                },
                "statistics": stats,
                "detailed_results": all_results,
            },
            f,
            ensure_ascii=False,
            indent=2,
        )

    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"ì´ ìš”ì²­ ìˆ˜: {stats['total_requests']}")
    print(f"ì„±ê³µí•œ ìš”ì²­: {stats['successful_requests']}")
    print(f"ì‹¤íŒ¨í•œ ìš”ì²­: {stats['failed_requests']}")
    print(f"ì´ ì†Œìš” ì‹œê°„: {stats['total_time']:.2f}ì´ˆ")
    print(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {stats['avg_processing_time']:.2f}ì´ˆ")
    print(f"í‰ê·  ì—°ê²° ì‹œê°„: {stats['avg_connection_time']:.2f}ì´ˆ")
    print(f"ì´ˆë‹¹ ì²˜ë¦¬ ìš”ì²­ ìˆ˜: {stats['requests_per_second']:.2f}")

    print("\nğŸ” ê²€ìƒ‰ íƒ€ì…ë³„ ì„±ëŠ¥:")
    for search_type, type_stats in search_type_stats.items():
        print(f"\n{search_type} ê²€ìƒ‰:")
        print(f"  ì´ ìš”ì²­: {type_stats['total']}")
        print(f"  ì„±ê³µ: {type_stats['success']}")
        print(f"  ì„±ê³µë¥ : {type_stats['success_rate']*100:.1f}%")
        print(f"  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {type_stats['avg_processing_time']:.2f}ì´ˆ")

    print("\nâŒ ì—ëŸ¬ íƒ€ì…ë³„ ë¶„ì„:")
    for error_type, count in stats["error_types"].items():
        print(f"{error_type}: {count}ê±´")

    # ì‹¤íŒ¨í•œ ìš”ì²­ ìƒì„¸ ì •ë³´ ì¶œë ¥
    if failed_requests:
        print("\nâŒ ì‹¤íŒ¨í•œ ìš”ì²­ ìƒì„¸ ì •ë³´:")
        for i, failed in enumerate(failed_requests, 1):
            print(f"\nì‹¤íŒ¨ #{i}")
            print(f"ê²€ìƒ‰ì–´: {failed['query']}")
            print(f"ê²€ìƒ‰ íƒ€ì…: {failed['search_type']}")
            print(f"ìƒíƒœ ì½”ë“œ: {failed['status_code']}")
            print(f"ì²˜ë¦¬ ì‹œê°„: {failed['processing_time']:.2f}ì´ˆ")
            print(f"ì—°ê²° ì‹œê°„: {failed['connection_time']:.2f}ì´ˆ")
            print(f"ì—ëŸ¬ íƒ€ì…: {failed.get('error_type', 'unknown')}")
            print(f"ì—ëŸ¬ ë©”ì‹œì§€: {failed['error']}")

    print(f"\nìƒì„¸ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {result_file}")

    return stats


def main():
    # API ì„œë²„ ìƒíƒœ í™•ì¸
    if not check_api_health():
        print("\nâš ï¸ API ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return

    # ë‹¤ì–‘í•œ ì‚¬ìš©ì ìˆ˜ì™€ ìš”ì²­ ìˆ˜ë¡œ í…ŒìŠ¤íŠ¸
    test_scenarios = [
        (10, 1),  # 10ëª…ì´ ê°ê° 1ê°œ ìš”ì²­
    ]

    print("\nğŸš€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")

    for num_users, num_requests in test_scenarios:
        print(f"\n{'='*50}")
        print(f"í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤: {num_users}ëª…ì˜ ì‚¬ìš©ì, ê° {num_requests}ê°œ ìš”ì²­")
        print(f"{'='*50}")

        run_concurrent_test(num_users, num_requests)

        # ê° ì‹œë‚˜ë¦¬ì˜¤ ì‚¬ì´ì— ì ì‹œ ëŒ€ê¸°
        time.sleep(10)  # ëŒ€ê¸° ì‹œê°„ ì¦ê°€


if __name__ == "__main__":
    main()
